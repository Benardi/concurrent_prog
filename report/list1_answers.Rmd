---
title: "Concurrent Programming - List 1"
author: Jos√© Benardi de Souza Nunes, Gustavo Diniz Monteiro, Ruan Roberto Eloy Silveira
output:   
  html_document:
    df_print: paged
    toc: yes
    toc_float: yes
---

<br>
<br>

```{r, include=TRUE, results='hide', message=F, warning=FALSE}
library(here)
library(boot)
library(readr)
library(dplyr)
library(ggplot2)
library(lubridate)

theme_set(theme_bw())
```

<br>

***

<br>

# Question 1

<br>

## Implementation

In this problem let us compare two versions of a program that's supposed to  count to 3E7 by means of three threads:   

* The `unprotected` version where no measure is taken to curb the behavior of threads  

* The `protected` version where measures are taken to prevent one thread from messing with the work of the others

<br>

### Unprotected version

* Code can be found at `code/unprotected_ex1.c`


```{c, eval=FALSE, code = readLines(here::here("code/unprotected_ex1.c"))}

```

<br>

### Protected version

* Code can be found at `code/protected_ex1.c`


```{c, eval=FALSE, code = readLines(here::here("code/protected_ex1.c"))}

```

<br>

## Performance comparison

<br>

##### To compare how each version fares performance wise let's check the results of the following experiment:

<br>

Factors:

* `version`: where the program is 'protected' or 'unprotected'

<br>

Metrics:

* `RSS` : Maximum resident set size of the process during its lifetime, in Kilobytes.
* `elapsed` : Elapsed real (wall clock) time used by the process, in [hours:]minutes:seconds.
* `cpu.sys` : Total number of CPU-seconds used by the system on behalf of the process (in kernel mode), in seconds.
* `.user` : Total number of CPU-seconds that the process used directly (in user mode), in seconds.
* `minor_pagefault` : Number of minor, or recoverable, page faults.  These are pages that are not valid (so they fault) but which have not yet been claimed by other virtual pages.  Thus the data in the page is still valid but the system tables must be updated.
* `major_pagefault` : Number of major, or I/O-requiring, page faults that occurred while the process was running.  These are faults where the page has actually migrated out of primary memory. 
* `inv_cxt_sw` : Number of times the process was context-switched involuntarily (because the time slice expired).
* `vol_cxt_sw` : Number of times that the program was context-switched voluntarily, for instance while waiting for an I/O operation to complete
* `execution` : Number of the execution

<br>

> For each combination of factor levels we had 50 repetitions, which gives us 100 executions.

<br>

### Load Data

```{r}
read_csv(here::here("output/perf_result.csv"),
         progress = F,
         col_types = cols(
           RSS = col_integer(),
           elapsed = col_character(),
           cpu.sys = col_double(),
           .user = col_double(),
           minor_pagefault = col_integer(),
           major_pagefault = col_integer(),
           inv_cxt_sw = col_integer(),
           vol_cxt_sw = col_integer(),
           version = col_character(),
           execution = col_integer())) %>% 
  mutate(elapsed = lubridate::ms(elapsed),
         version = as.factor(version)) %>% 
  mutate(elapsed = lubridate::second(elapsed)) -> perf_data 

perf_data %>%
  glimpse()
```

<br>

### Elapsed Time

<br>

#### Descriptive Analysis

```{r}
perf_data %>%
  ggplot(aes(execution,elapsed,color=version)) +
    geom_segment(aes(x = execution, y = 0,
                     xend = execution, yend = elapsed),
                 color = "grey50", size=0.06) +
  geom_point(size=2) +
  labs(x="Execution",title="(Chart 1) Elapsed time by execution")
```

* We can notice a substantially longer elapsed time in the executions of the `unprotected` version compared to the `protected` one.

<br>

```{r}
perf_data %>%
  ggplot(aes(version,elapsed)) +
  geom_boxplot() +
  labs(title="(Chart 2) Interquatile range by program version")
```

* Results similar to those of *Chart 1*.

<br>

#### Statistical Inference

```{r}
my_theta <- function(x, i) {
    x %>% 
        slice(i) -> d
  
    d %>% 
      group_by(version) %>% 
      summarise(med = median(elapsed, na.rm = TRUE)) -> y
    
    med_diff = y[y$version == "protected",]$med - y[y$version == "unprotected",]$med
    
    return(med_diff)
}

med_diff.boot <- boot(data = perf_data, 
                 statistic = my_theta, 
                 R = 2000)

plot(med_diff.boot)
```

* We have a weird-tailed distributions that quite deviates from the normal, looking at the density plot it's most likely due to a lack of variance, for this reason let's use the `basic CI` (also called pivotal or empirical CI) to extract our results. 


```{r}
result_med_diff <- boot.ci(boot.out = med_diff.boot, 
        conf = 0.95, 
        type = "basic")

result_med_diff
```

```{r}
X2.5 = c(result_med_diff$basic[4])
X97.5 = c(result_med_diff$basic[5])
elapsed.diff = data.frame(X2.5,X97.5)

elapsed.diff %>%
  ggplot(aes(x = "( protected - unprotected )",
             ymin = X2.5, ymax = X97.5)) +
  geom_errorbar(width = .2) +
  geom_hline(yintercept = 0, colour = "darkorange") +
  labs(x="", y="elapsed (difference)") +
    ggtitle("(Chart 3) C.I. for the difference of the median")
```

##### Regarding the difference between `protected` and `unprotected` versions in median elapsed time, we can conclude that:

* As the C.I. does not intersect 0, we can say that it's statistically significant 
    + the protected version is faster than the unprotected one.

* The difference is also relevant 
    + A difference of at least  0.6 (high end of the CI) represents both nearly half the median elapsed time of the `unprotected` version and nearly all the elapsed time of the `protected` version, *see Chart 2*.

> The protected version is faster than the unprotected one.

<br>

### Explanation (why the difference?)

```{r}
perf_data %>%
  ggplot(aes(execution,inv_cxt_sw,color=version)) +
    geom_segment(aes(x = execution, y = 0,
                     xend = execution, yend = inv_cxt_sw),
                 color = "grey50", size=0.12) +
  geom_point(size=2) +
  labs(x="Execution", y="# context switches",
       title="(Chart 4) Involutary context switches by execution")
```

* There seems to be a substantial difference in the number of involuntary context switches each version is subjected to. The `unprotected` version seems to have experienced a much larger number of **involutary context switches**, which would account for the difference in elapsed time.

<br>

#### Statistical Inference

```{r}
my_theta <- function(x, i) {
    x %>% 
        slice(i) -> d
  
    d %>% 
      group_by(version) %>% 
      summarise(med = median(inv_cxt_sw, na.rm = TRUE)) -> y
    
    med_diff = y[y$version == "protected",]$med - y[y$version == "unprotected",]$med
    
    return(med_diff)
}

med_inv_sw.boot <- boot(data = perf_data, 
                 statistic = my_theta, 
                 R = 2000)

plot(med_inv_sw.boot)
```

* We have a somewhat weird-tailed distributions, for this reason let's use the `basic CI` (also called pivotal or empirical CI) to extract our results. 


```{r}
result_med_inv_sw <- boot.ci(boot.out = med_inv_sw.boot, 
        conf = 0.95, 
        type = "basic")

result_med_inv_sw
```

```{r}
X2.5 = c(result_med_inv_sw$basic[4])
X97.5 = c(result_med_inv_sw$basic[5])
inv_sw.diff = data.frame(X2.5,X97.5)

inv_sw.diff %>%
  ggplot(aes(x = "(protected - unprotected)",
             ymin = X2.5, ymax = X97.5)) +
  geom_errorbar(width = .2) +
  geom_hline(yintercept = 0, colour = "darkorange") +
  labs(x="", y="inv_cxt_sw (difference)") +
    ggtitle("(Chart 5) C.I. for the difference of the median")
```

##### Regarding the difference between `protected` and `unprotected` versions in median number of involuntary context switches, we can conclude that:

* As the C.I. does not intersect 0, we can say that it's statistically significant 
    + The `protected` version experienced less involuntary context switches than the `unprotected` one.
* By the scale of the C.I. we can say that it's also relevant. 

<<<<<<< HEAD
> So, we can point the difference in the number of involuntary context switches as evidence for the disparity in elapsed time between program versions.   

<br>

***

<br>

# Question 3

<br>

## C version

<br>


### Returns first result

<br>

* Code can be found at `code/returns_first_ex3.c`

```{c, eval=FALSE, code = readLines(here::here("code/returns_first_ex3.c"))}

```

<br>

### Returns combined result

<br>

* Code can be found at `code/returns_combined_ex3.c`

```{c, eval=FALSE, code = readLines(here::here("code/returns_combined_ex3.c"))}

```

<br>

## Java version

<br>

### Returns first result

<br>

* Code can be found at :
  + `java-code/src/ex_03/first_return/Main.java`
  + `java-code/src/ex_03/first_return/Requester.java`

<br>

#### Requester

```{r, eval=FALSE, code = readLines(here::here("java-code/src/ex_03/first_return/Requester.java"))}

```

<br>

#### Main

```{r, eval=FALSE, code = readLines(here::here("java-code/src/ex_03/first_return/Main.java"))}

```

### Returns combined result

<br>

* Code can be found at :
  + `java-code/src/ex_03/combined_return/CombinedRequester.java`
  + `java-code/src/ex_03/combined_return/CombinedMain.java`


<br>

#### Requester

```{r, eval=FALSE, code = readLines(here::here("java-code/src/ex_03/combined_return/CombinedRequester.java"))}

```

<br>

#### Main

```{r, eval=FALSE, code = readLines(here::here("java-code/src/ex_03/combined_return/CombinedMain.java"))}

```

<br>

***

<br>

# Question 4

<br>

## C version

<br>


### Returns first result

<br>

* Code can be found at `code/returns_first_ex4.c`

```{c, eval=FALSE, code = readLines(here::here("code/returns_first_ex4.c"))}

```

<br>

### Returns combined result

<br>

* Code can be found at `code/returns_combined_ex4.c`

```{c, eval=FALSE, code = readLines(here::here("code/returns_combined_ex4.c"))}

```



=======
> So, we can point the difference in the number of involuntary context switches as evidence for the disparity in elapsed time between program versions.

# Question 5

##### The data set shows the results of an experiment in which the performances of 4 collections were measured, the experiment consisted of the insertion of competing reading / writing of elements (between 200-2000) in the collection with different numbers of threads (1, 4, 7 or 10) and with different writing / reading ratios (100/0 - 75/25 - 50/50 - 25/75 respectively) of different amounts of elements.

```{r}
read_csv(here::here("output/report.csv")) %>%
  mutate(total_time= total_time / 1000000) -> data

glimpse(data)
```
```{r}
data %>%
  ggplot(aes(y = class, x = total_time)) +
  geom_point() +
  facet_wrap(~threads)
```
##### By exploring the data more generally, we can easily see the impact that the use of more threads at the same time causes on the performance of certain collections, such as the `CopyOnWriteArrayList` case.
##### The `SynchronizedRandomAccessList` case, however, seems to have an overall improvement when used with more than one thread, but when this number of theads increases too much, it tends to suffer from the overhead caused by the synchronization work.
##### Also noteworthy is how map-based collections perform better than list-based collections in all cases.

```{r}
data %>%
  ggplot(aes(y = total_time, x = elements, group=elements)) +
  geom_boxplot() +
  facet_wrap(~class,scales = "free")
```


```{r}
data %>% 
  ggplot(aes(y = class, x = total_time)) + 
  geom_point() + facet_wrap(~write_level)
```

```{r}
data %>% 
  filter(class != 'CopyOnWriteArrayList') %>% 
  filter(class != 'SynchronizedRandomAccessList') %>% 
  ggplot(aes(y = class, x = total_time)) + 
  geom_point() + facet_wrap(~write_level) +
  geom_jitter()
```

```{r}
data %>% 
  filter(class != 'ConcurrentHashMap') %>% 
  filter(class != 'SynchronizedMap') %>% 
  ggplot(aes(y = class, x = total_time)) + 
  geom_point() + facet_wrap(~write_level) +
  geom_jitter()
```

```{r}
data %>% 
  ggplot(aes(x =threads, y = total_time)) +
  geom_point() +
  facet_wrap(~class)
```

```{r}
data %>%
  filter(class != 'ConcurrentHashMap') %>% 
  filter(class != 'SynchronizedMap') %>% 
  ggplot(aes(x =threads, y = total_time)) +
  geom_point() +
  facet_wrap(~class)
```

```{r}
data %>%
  filter(class != 'CopyOnWriteArrayList') %>% 
  filter(class != 'SynchronizedRandomAccessList') %>% 
  ggplot(aes(x =threads, y = total_time)) +
  geom_point() +
  facet_wrap(~class)
```
>>>>>>> a84a961... Add new plots for question 5 and some explanations.

