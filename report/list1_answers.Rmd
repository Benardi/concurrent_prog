---
title: "Concurrent Programming - List 1"
author: Jos√© Benardi de Souza Nunes, Gustavo Diniz Monteiro, Ruan Roberto Eloy Silveira
output:
  html_document:
    df_print: paged
    toc: yes
    toc_float: yes

---

<br>
<br>

```{r, include=TRUE, results='hide', message=F, warning=FALSE}
library(here)
library(boot)
library(readr)
library(dplyr)
library(ggplot2)
library(lubridate)

theme_set(theme_bw())
```

<br>

***

<br>

# Question 1

<br>

## Implementation

In this problem let us compare two versions of a program that's supposed to  count to 3E7 by means of three threads:   

* The `unprotected` version where no measure is taken to curb the behavior of threads  

* The `protected` version where measures are taken to prevent one thread from messing with the work of the others

<br>

### Unprotected version

* Code can be found at `c-code/unprotected_ex1.c`


```{c, eval=FALSE, code = readLines(here::here("c-code/unprotected_ex1.c"))}

```

<br>

### Protected version

* Code can be found at `c-code/protected_ex1.c`


```{c, eval=FALSE, code = readLines(here::here("c-code/protected_ex1.c"))}

```

<br>

## Performance comparison

<br>

##### To compare how each version fares performance wise let's check the results of the following experiment:

<br>

Factors:

* `version`: where the program is 'protected' or 'unprotected'

<br>

Metrics:

* `RSS` : Maximum resident set size of the process during its lifetime, in Kilobytes.
* `elapsed` : Elapsed real (wall clock) time used by the process, in [hours:]minutes:seconds.
* `cpu.sys` : Total number of CPU-seconds used by the system on behalf of the process (in kernel mode), in seconds.
* `.user` : Total number of CPU-seconds that the process used directly (in user mode), in seconds.
* `minor_pagefault` : Number of minor, or recoverable, page faults.  These are pages that are not valid (so they fault) but which have not yet been claimed by other virtual pages.  Thus the data in the page is still valid but the system tables must be updated.
* `major_pagefault` : Number of major, or I/O-requiring, page faults that occurred while the process was running.  These are faults where the page has actually migrated out of primary memory. 
* `inv_cxt_sw` : Number of times the process was context-switched involuntarily (because the time slice expired).
* `vol_cxt_sw` : Number of times that the program was context-switched voluntarily, for instance while waiting for an I/O operation to complete
* `execution` : Number of the execution

<br>

> For each combination of factor levels we had 50 repetitions, which gives us 100 executions.

<br>

### Load Data

```{r}
read_csv(here::here("output/perf_result.csv"),
         progress = F,
         col_types = cols(
           RSS = col_integer(),
           elapsed = col_character(),
           cpu.sys = col_double(),
           .user = col_double(),
           minor_pagefault = col_integer(),
           major_pagefault = col_integer(),
           inv_cxt_sw = col_integer(),
           vol_cxt_sw = col_integer(),
           version = col_character(),
           execution = col_integer())) %>% 
  mutate(elapsed = lubridate::ms(elapsed),
         version = as.factor(version)) %>% 
  mutate(elapsed = lubridate::second(elapsed)) -> perf_data 

perf_data %>%
  glimpse()
```

<br>

### Elapsed Time

<br>

#### Descriptive Analysis

```{r}
perf_data %>%
  ggplot(aes(execution,elapsed,color=version)) +
    geom_segment(aes(x = execution, y = 0,
                     xend = execution, yend = elapsed),
                 color = "grey50", size=0.06) +
  geom_point(size=2) +
  labs(x="Execution", y= "Elapsed time (s)",
       title="(Chart 1) Elapsed time by execution")
```

* We can notice a substantially longer elapsed time in the executions of the `unprotected` version compared to the `protected` one.

<br>

```{r}
perf_data %>%
  ggplot(aes(version,elapsed)) +
  geom_boxplot() +
  labs(y="Elapsed time (s)",x="program version",
       title="(Chart 2) Interquatile range by program version")
```

* Results similar to those of *Chart 1*.

<br>

#### Statistical Inference

```{r}
my_theta <- function(x, i) {
    x %>% 
        slice(i) -> d
  
    d %>% 
      group_by(version) %>% 
      summarise(med = median(elapsed, na.rm = TRUE)) -> y
    
    med_diff = y[y$version == "protected",]$med - y[y$version == "unprotected",]$med
    
    return(med_diff)
}

med_diff.boot <- boot(data = perf_data, 
                 statistic = my_theta, 
                 R = 2000)

plot(med_diff.boot)
```

* We have a weird-tailed distributions that quite deviates from the normal, looking at the density plot it's most likely due to a lack of variance, for this reason let's use the `basic CI` (also called pivotal or empirical CI) to extract our results. 


```{r}
result_med_diff <- boot.ci(boot.out = med_diff.boot, 
        conf = 0.95, 
        type = "basic")

result_med_diff
```

```{r}
X2.5 = c(result_med_diff$basic[4])
X97.5 = c(result_med_diff$basic[5])
elapsed.diff = data.frame(X2.5,X97.5)

elapsed.diff %>%
  ggplot(aes(x = "( protected - unprotected )",
             ymin = X2.5, ymax = X97.5)) +
  geom_errorbar(width = .2) +
  geom_hline(yintercept = 0, colour = "darkorange") +
  labs(x="", y="elapsed time (difference)") +
    ggtitle("(Chart 3) C.I. for the difference of the median")
```

##### Regarding the difference between `protected` and `unprotected` versions in median elapsed time, we can conclude that:

* As the C.I. does not intersect 0, we can say that it's statistically significant 
    + the protected version is faster than the unprotected one.

* The difference is also relevant 
    + A difference of at least  0.6 (high end of the CI) represents both nearly half the median elapsed time of the `unprotected` version and nearly all the elapsed time of the `protected` version, *see Chart 2*.

> The protected version is faster than the unprotected one.

<br>

### Explanation (why the difference?)

```{r}
perf_data %>%
  ggplot(aes(execution,inv_cxt_sw,color=version)) +
    geom_segment(aes(x = execution, y = 0,
                     xend = execution, yend = inv_cxt_sw),
                 color = "grey50", size=0.12) +
  geom_point(size=2) +
  labs(x="Execution", y="# context switches",
       title="(Chart 4) Involutary context switches by execution")
```

* There seems to be a substantial difference in the number of involuntary context switches each version is subjected to. The `unprotected` version seems to have experienced a much larger number of **involutary context switches**, which would account for the difference in elapsed time.

<br>

#### Statistical Inference

```{r}
my_theta <- function(x, i) {
    x %>% 
        slice(i) -> d
  
    d %>% 
      group_by(version) %>% 
      summarise(med = median(inv_cxt_sw, na.rm = TRUE)) -> y
    
    med_diff = y[y$version == "protected",]$med - y[y$version == "unprotected",]$med
    
    return(med_diff)
}

med_inv_sw.boot <- boot(data = perf_data, 
                 statistic = my_theta, 
                 R = 2000)

plot(med_inv_sw.boot)
```

* We have a somewhat weird-tailed distributions, for this reason let's use the `basic CI` (also called pivotal or empirical CI) to extract our results. 


```{r}
result_med_inv_sw <- boot.ci(boot.out = med_inv_sw.boot, 
        conf = 0.95, 
        type = "basic")

result_med_inv_sw
```

```{r}
X2.5 = c(result_med_inv_sw$basic[4])
X97.5 = c(result_med_inv_sw$basic[5])
inv_sw.diff = data.frame(X2.5,X97.5)

inv_sw.diff %>%
  ggplot(aes(x = "(protected - unprotected)",
             ymin = X2.5, ymax = X97.5)) +
  geom_errorbar(width = .2) +
  geom_hline(yintercept = 0, colour = "darkorange") +
  labs(x="", y="inv_cxt_sw (difference)") +
    ggtitle("(Chart 5) C.I. for the difference of the median")
```

##### Regarding the difference between `protected` and `unprotected` versions in median number of involuntary context switches, we can conclude that:

* As the C.I. does not intersect 0, we can say that it's statistically significant 
    + The `protected` version experienced less involuntary context switches than the `unprotected` one.
* By the scale of the C.I. we can say that it's also relevant. 

> So, we can point the difference in the number of involuntary context switches as evidence for the disparity in elapsed time between program versions.   

<br>

***

<br>

# Question 2

<br>

* Code can be found at `java-code/src/list-1/ex_02`

<br>

***

<br>

# Question 3

<br>

## C version

<br>


### Returns first result

<br>

* Code can be found at `c-code/returns_first_ex3.c`

```{c, eval=FALSE, code = readLines(here::here("c-code/returns_first_ex3.c"))}

```

<br>

### Returns combined result

<br>

* Code can be found at `c-code/returns_combined_ex3.c`

```{c, eval=FALSE, code = readLines(here::here("c-code/returns_combined_ex3.c"))}

```

<br>

## Java version

<br>

### Returns first result

<br>

* Code can be found at :
  + `java-code/src/list-1/ex_03/first_return/Main.java`
  + `java-code/src/list-1/ex_03/first_return/Requester.java`

<br>

#### Requester

```{r, eval=FALSE, code = readLines(here::here("java-code/src/list-1/ex_03/first_return/Requester.java"))}

```

<br>

#### Main

```{r, eval=FALSE, code = readLines(here::here("java-code/src/list-1/ex_03/first_return/Main.java"))}

```

### Returns combined result

<br>

* Code can be found at :
  + `java-code/src/list-1/ex_03/combined_return/CombinedRequester.java`
  + `java-code/src/list-1/ex_03/combined_return/CombinedMain.java`


<br>

#### Requester

```{r, eval=FALSE, code = readLines(here::here("java-code/src/list-1/ex_03/combined_return/CombinedRequester.java"))}

```

<br>

#### Main

```{r, eval=FALSE, code = readLines(here::here("java-code/src/list-1/ex_03/combined_return/CombinedMain.java"))}

```

<br>

***

<br>

# Question 4

<br>

## C version

<br>


### Returns first result

<br>

* Code can be found at `c-code/returns_first_ex4.c`

```{c, eval=FALSE, code = readLines(here::here("c-code/returns_first_ex4.c"))}

```

<br>

### Returns combined result

<br>

* Code can be found at `c-code/returns_combined_ex4.c`

```{c, eval=FALSE, code = readLines(here::here("c-code/returns_combined_ex4.c"))}

```

<br>

## Java version

<br>

### Returns first result

<br>

* Code can be found at `java-code/src/list-1/ex_04/ReturnFirst.java`

<br>

```{r, eval=FALSE, code = readLines(here::here("java-code/src/list-1/ex_04/ReturnFirst.java"))}

```


### Returns combined result

<br>

* Code can be found at `java-code/src/list-1/ex_04/ReturnFirstCombined.java`

<br>


```{r, eval=FALSE, code = readLines(here::here("java-code/src/list-1/ex_04/ReturnFirstCombined.java"))}

```


<br>

***

<br>

# Question 5

<br>

## Experiment Design

<br>

The data set shows the results of the experiment which consists in the insertion of elements in a collection with different numbers of threads:

Factors:

* `Collection`: Which collection is being measured
      +  ConcurrentHashMap, SynchronizedMap, CopyOnWriteArrayList, SynchronizedRandomAccessList
  
* `Write Level`: Ratio of write/read operations
      + Level 1: 75% read 25% write
      + Level 2 = 50% read 50% write
      + Level 3 = 25% read 75% write
      + Level 4 = 100% write

  
* `Number of elements`: Number of elements added to the collection
      + 50, 100, 150, 200, 250, 300, 350, 400, 450, 500
    
Metrics:

* `Total Time`: Time taken to perform a batch of operations

<br>

## Implementation

* Code used to generate dataset can be found at `java-code/src/list-1/ex_05/Main.java`

```{c, eval=FALSE, code = readLines(here::here("java-code/src/list-1/ex_05/Main.java"))}

```

<br>

## Result Analysis

<br>

```{r}
read_csv(here::here("output/report.csv"),
         col_types = cols(
           class = col_character(),
           elements = col_integer(),
           total_time = col_double(),
           threads = col_integer(),
           write_level = col_integer()),
         progress = F) %>%
  mutate(total_time = total_time / 1000000) -> data

data %>%
  glimpse()
```

```{r}
data %>%
  ggplot(aes(total_time,class)) +
  geom_point() +
  facet_wrap(~threads, labeller = "label_both") +
  labs(x="Total Time (ms)",y="Collection")
```

* Map-based collections perform better than list-based collections in all cases.
* By exploring the data from a more general point of view, we can easily see the impact that the use of more threads simultaneously causes on the performance of certain collections, such as the `CopyOnWriteArrayList` case.

<br>

* In the `SynchronizedRandomAccessList` case, however: 

    + There seems to happen an overall improvement when used with more than one thread, 
    + Nonetheless, when this number of theads increases too much, it tends to suffer from the overhead caused by the synchronization work.

<br>

### Number of elements

<br>

```{r}
data %>%
  ggplot(aes(y = total_time, x = elements, group=elements)) +
  geom_boxplot() +
  facet_wrap(~class, scales = "free") +
  labs(x="Number of elements", y="Total time (ms)")
```

* We can see that the total execution time for the **list-based** collections grows linearly with the number of elements inserted 
* The total execution of map-based collections doesn't seem rather random than related to the number of elements

<br>

> Because lists and maps have very different performance, we will keep them in different separate charts from now on.

<br>

### Write Level

<br>

```{r}
data %>%
  filter(class != 'CopyOnWriteArrayList') %>% 
  filter(class != 'SynchronizedRandomAccessList') %>% 
  ggplot(aes(y = class, x = total_time)) +
  geom_point() + 
  facet_wrap(~write_level, labeller="label_both") +
  labs(y="Collection", x="Total time (ms)")
```

* The proportion of writing and reading does not appear to consistently impact the performance of map-based collections as shown below with list-based collections

```{r}
data %>%
  filter(class != 'ConcurrentHashMap') %>% 
  filter(class != 'SynchronizedMap') %>% 
  ggplot(aes(y = class, x = total_time)) +
  geom_point() + 
  facet_wrap(~write_level, labeller="label_both") +
  labs(y="Collection", x="Total time (ms)")
```

* In the lists the proportion of writing impacts greatly by the increase of elements themselves.

<br>

### Number of threads

<br>

```{r}
data %>%
  filter(class != 'ConcurrentHashMap') %>% 
  filter(class != 'SynchronizedMap') %>% 
  ggplot(aes(x =threads, y = total_time)) +
  scale_x_continuous(breaks=seq(1, 10, 3)) +
  geom_point() +
  facet_wrap(~class) +
  labs(x="Number of threads", y="Total time (ms)")
```

* In list-based collections, the impact caused by the increase in number threads seems much more explicit and follows a near-linear growth.


```{r}
data %>%
  filter(class != 'CopyOnWriteArrayList') %>% 
  filter(class != 'SynchronizedRandomAccessList') %>% 
  ggplot(aes(x =threads, y = total_time)) +
    scale_x_continuous(breaks=seq(1, 10, 3)) +
  geom_point() +
  facet_wrap(~class) +
  labs(x="Number of threads", y="Total time (ms)")
```

*  In map-based collections the number of threads seems to have some impact but it does not follow a pattern, probably caused by the impact of thread synchronization.

<br>

## Summary

<br>

##### In general we can conclude that for **list-based** collections:

* The number of threads impact the performance of the collections, such as CopyOnWriteArrayList whose performance worsens as the number of threads increases.

* The SynchronizedRandomAccessList whose performance seems to improve when its number of threads increases from a single thread to a few ones. Later, as the number of threads increases greatly their performance degraded.

##### In general we can conclude that for **map-based** collections: 

* The impact of the number of theads seems to be smaller and more random, probably caused by synchronization and moments where multiple threads are locked at the same time. 